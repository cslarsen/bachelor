\chapter{Analysis}

Here we will look at the performance profile of our various configurations.
Note that we are running everything on a software network simulator, and
therefore these performance tests will only be useful for giving us an
indication of \textit{relative} performances.

Therefore we will first need to establish a baseline for the system as it
is. We should then be able to compare various configurations against it.

\todo{Når ferdig, test med ekte software som MySQL, osv osv.}

For reference, the teste have been run on an Ubuntu GNU/Linux VM from the
Mininet site, loaded with our code and running in VirtualBox on a Mac OS X
laptop.

\section{Baseline --- ICMP ping on L2 learning switch using flow tables}

The most basic setup we can test against is using our L2 learning switch
from chapter \ref{chapter:l2.learning.switch}
\vpageref{chapter:l2.learning.switch}.  This is fundamental to all our
configurations, because they all use it to make sure that packets are routed
correctly.

We will use the topology given in figure \ref{figure:baseline.topology}.

\begin{figure}
  \centering
  \begin{tikzpicture}[
    every node/.style={draw, circle},
    x=0.6cm,
    y=0.6cm]

    % Switches
    \foreach \n in {1,2,3} {
      \pgfmathsetmacro\x{(\n-2)*6}

      % Switch
      \node (S\n) at (\x ,  0) {$S_\n$};

      % Controller
      \node (C\n) at (\x ,  2) {$C_\n$};
      \draw (S\n) -- (C\n);

      % Hosts
      \foreach \h in {1,2,3} {
        \pgfmathsetmacro\pos{(\h - 2)*2}
        \pgfmathtruncatemacro\num{((\n - 1)*3) + int(\h)}

        % Host node
        \node (h\num) at (\x + \pos, -2) {$h_{\num}$};
        \draw (S\n) -- (h\num);
      }
    }

    % Switch links
    \draw (S1) to[out=10,in=170]
               node[below=-0.5cm, draw=none] {$l_1 = 5~ms$} (S2);

    \draw (S2) to[out=10,in=170]
               node[below=-0.5cm, draw=none] {$l_2 = 5~ms$} (S3);

    % Mark traversal path
    \draw [very thick] (h1) -- node[left,draw=none] {$l_0=5~ms$} (S1);
    \draw [very thick] (S1) -- node[left,draw=none] {$l_{C_1} \approx 0~ms$} (C1);
    \draw [very thick] (S1) to[out=10,in=170] (S2);

    \draw [very thick] (S2) -- node[left,draw=none] {$l_{C_2} \approx 0~ms$} (C2);
    \draw [very thick] (S2) to[out=10,in=170] (S3);

    \draw [very thick] (S3) -- node[left,draw=none] {$l_{C_3} \approx 0~ms$} (C3);
    \draw [very thick] (S3) -- node[right,draw=none] {$l_4=5~ms$} (h9);
  \end{tikzpicture}
  \caption{Baseline topology with three switches $S$ and their controllers
    $C$.  The client $c_0$ will send ICMP ping packets to the farthest node
      $h_9$.  The packets will go through three links with a configured
      latency of $5~ms$.}
  \label{figure:baseline.topology}
\end{figure}

Before we present the results, let's look at what we should expect from the
configuration above.  The three links the packets need to cross each have
$5~ms$ latency.  There is some latency in each switch and in each end of the
link ($c_0$ and $h_9$) as well as between and in the switches and their
controllers.

In total, one would expect the \acf{RTT} to be
\begin{gather}
  RTT_{c_0, h_9} = 2\left( \sum l + \sum P_S + \sum P_C \right) + P_{c_0} + P_{h_9} + K
  \label{equation:baseline.rtt}
\end{gather}%
that is, the latencies for all links $l$, processing time $P$ for
$S,C,c_0,h_9$ and a constant $K$ for inherent latency in the software
environment (Mininet, Open vSwitch and VirtualBox).  Equation
\ref{equation:baseline.rtt} is loosely based on
\cite{DBLP:conf/cnsm/PhemiusB13}.
\todo{Refiner formel, den kan ha feil!}

For simplicity, we will set $P_{c_0},~P_{h_9},~l_{C_1},~l_{C_2}~\text{and}~
l_{C_3}$ to zero.\footnote{When flow table entries are installed, one should
see very little traffic going to the controllers, meaning that we can
assume that $l_{C} \to 0$ after the tables are warmed up.
There are still events that are being sent from the switches to the
controllers, though.}
For consistency, we have removed the fall--back link
between $S_1$ and $S_3$ (figure \ref{figure:graph.three.switches}).
We could attempt to measure $K$ by running Mininet with two nodes linked
with zero bandwidth, but we will simply set it to zero as well.

Filling in the known values gives
\begin{gather}
  RTT_{c_0,h_9} = 40~ms + 2\left( P_S + P_C \right)
  \\
  RTT_{c_0,h_9} = 40~ms + 2L~\text{where}~L = P_S + P_C
  \label{equation:expected.baseline.rtt}
\end{gather}

We will now use the BSD \texttt{ping} command to send out packets every
$10~ms$.  The controller will install flow tables with idle and hard timeout
set to one hour.  Remember that there is some inherent noise in the system
as, e.g., ARP--packets will need to be exchanged.  The installed flow
entries will match on as many fields as possible.\todo{Cite kildekode
som vi bruker, flow installation er tatt fra POX sin l2 switch.}

On the thesis VM (for installation instructions, see chapter
\ref{chapter:install.vm}), this test can be run by opening two consoles on
and starting the POX controller first and then Mininet.

\begin{Verbatim}
# Console 1 (start first)
$ ssh mininet make bench-baseline-pox

# Console 2 (start after POX is up)
$ ssh mininet make bench-baseline-mininet
\end{Verbatim}

The results can be seen in figure
\ref{benchmark:l2.learning.switch.ping}
\vpageref{benchmark:l2.learning.switch.ping}.

We measured the \ac{RTT} and divided it by two to get an indication of the
one--way latency.\footnote{We cannot measure the \textit{true} one--way
latency, but we feel this is a good enough measure for our needs.}
\todo{Tror det er bedre å bare bruke RTT og ikke dele på to.}

An ICMP ping packet was sent every $10~ms$ with no other traffic on the
system.\footnote{Except for background noise like ARP--packets.  One can
clearly see these in the logs for the controller.}

The hard timeout for the flow table entries was set to ten seconds.  These
can clearly be seen as spikes in the plot.

\begin{figure}
  \centering
  \includegraphics[width=\textwidth]{data/pings.eps}
  \caption{Latency of ICMP ping on L2 learning switch using flow tables.}
  \label{benchmark:l2.learning.switch.ping}
\end{figure}

The median value was $16.50~ms$, the mean was $16.79~ms$.
Its \ac{RMS},

\begin{gather}
  \sqrt{\frac{1}{|n]}\sum{n^2}}
  \label{equation:rms}
\end{gather}

was $17.00~ms$.
\todo{Remove outliers and show numbers.}
The minimum and maximum values were $15.30~ms$ and $50.50~ms$.
The 1st quartile was at $16.30~ms$ and its 3rd at $16.75~ms$ and its standard
deviation $\sigma = 2.665~ms$.

\todo{Bruk boxplot() i R når en skal sammenligne. Og hiv inn tall i tabell
  for sammenligning sammen med plot. Plot trenger ikke være gigantisk stor.}

\section{L2 learning switch, key--value store}
\label{chapter:benchmark.l2.kv.noflows}

First we need a baseline.  Here we have a topology of two switches $S_0$ and
$S_1$ with a controller each.  The switches has three hosts, $h_0, \dots, h_5$.
A client $c_0$ is connected to $S_0$. We're running Python
key--value--stores on each host, and $c_0$ will issue a get--request
followed by a put--request to the host $h_5$, which is connected to $S_1$.
We measure the time for each request, divide it
by two and call it latency.\footnote{We basically assume that the packets
take an equal amount of time back and forth, and divide by two to get this
time.}

There are two controllers $C_0$ and $C_1$ for the switches $S_0$ and $S_1$,
respectively.  In this situation, the packets from $c_0$ need to travel
over two switches.

The network is running on Mininet, a software network simulator, on a Linux
virtual machine running on an Mac OS X box.  All the links in Mininet have
been set up with $10 Mbit/s$ bandwidth, $5~ms$ latency and no packet
loss.  These links have been set up with \ac{HTB}
\cite{devera2002hierarchical} enabled, which Open vSwitch\index{Open vSwitch}
 uses for providing rate limiting.

In this first benchmark, the switches will send each packet up to the
controllers.  The controllers implement L2 learning switches and will not
install any flow table entries for rapid dispatch.

On the x--axis is the time in seconds.  On the y--axis is the latency for
get and put requests.

The result can be seen in figure \ref{benchmark:l2.learning.switch.no.flows} 
\vpageref{benchmark:l2.learning.switch.no.flows}.

What is surprising here is that the put--requests have much higher latency
than the get--requests. We don't know why this is.\todo{Finn ut! Er det pga
  pakkene er større? Eller andre grunner?}

\section{L2 learning switch, key--value store, flow entries}

We have the same setup as above, but this time we install flow entries that
will automatically forward the packets.  The flow table entries will match
on as many fields in the packets as possible.

The flow table entries have idle and hard timeouts set to 10 seconds.
In other words, we should be able to see some increased latency every ten
seconds.

% Present both plots together
\begin{figure}
  \centering
  \begin{subfigure}{\textwidth}
    \centering
    \includegraphics[width=\textwidth]{data/data2.eps}
    \caption{L2 learning switch without using flow tables.}
    \label{benchmark:l2.learning.switch.no.flows}
  \end{subfigure}

  \centering
  \begin{subfigure}{\textwidth}
    \centering
    \includegraphics[width=\textwidth]{data/data3.eps}
    \caption{L2 learning switch using flow tables.}
    \label{benchmark:l2.learning.switch.with.flows}
  \end{subfigure}
\end{figure}

The result can be seen in figure \ref{benchmark:l2.learning.switch.with.flows}
\vpageref{benchmark:l2.learning.switch.with.flows}.

Here we can see that the latency has been reduced somewhat.\todo{Hvor mye?
Hva med å plotte over hverandre, hva med å lage average eller root mean
square eller noe sånn?}

We also see some latency spikes around every ten seconds, as expected.

\todo{Plott med flere verdier, istedenfor å vise seconds på x--aksen kan vi
  vise elapsed time, som i at den starter på 0 sekunder.}

These two benchmarks will serve as a baseline to which we will compare our
performance when we enable Paxos on the switches.

Remember that when we run Paxos, we will still have to use the L2 learning
switch for the nodes to be able to communicate.

\todo{Trendlinjner, moving average, fitting osv... må ha det i grafene, må
  også ha litt statistisk analyse av tallene selv osv.}

\section{Three switches, Paxos on controller}

\todo{Få data}

\section{Three switches, Paxos on controller and flow table}

\todo{Få data}

\section{Other solutions}

We chose to use OpenFlow as the basis for our system.
We could just as well have used a networking system that already supported
programmability in some way, for instance the Intel DPDK\todo{Needs
citation}.\todo{Also needs defense.}

\todo{Flytt evt dette ned til improvements--delen}
