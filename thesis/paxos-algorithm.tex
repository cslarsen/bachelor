\section{Paxos pseudo--code}

Algorithm \ref{algorithm:paxos.full.proposer} is for the Paxos proposer
role.  \texttt{TRUST}--messages are received during phase 1a, and
\texttt{PROMISE}s are received during phase 2a \cite{Lam01}.  The algorithms
here are a slight variation of the ones given in \cite{Insane.Paxos}, which
in turn have been derived from \cite{renesse.paxos} and \cite{Lam01}.

\begin{algorithm}
  \caption{Classic crash Paxos --- Proposer $c$ (leader)}
  \label{algorithm:paxos.full.proposer}
  \begin{algorithmic}

    \State $A$ \Comment{Set of acceptors}
    \State $crnd \gets 0$ \Comment{Current round (unique)}
    \State

    \On{$\langle \texttt{TRUST}, c \rangle$}{$\Omega_c$}
      \State $crnd \gets \textbf{pickNext}(crnd)$ \Comment{Phase 1a}
      \State $MV \gets \emptyset$ \Comment{Set of $\langle round, vote\ value \rangle$ tuples}
      \State \SendTo{$\langle \texttt{PREPARE}, crnd \rangle$}{$A$}
    \EndOn
    \State

    \On{$\langle \texttt{PROMISE}, rnd, vrnd, vval \rangle$}
       {$\text{acceptor}\ a$} \Comment{Phase 2a}
      \If{$rnd = crnd$}
        \State $MV \gets MV \cup \langle vrnd, vval \rangle$
        \If{$|MV| \geq n_a - t_a$}
          \If{$(vrnd = \bot)\ \forall\ \langle vrnd, vval \rangle \in MV$}
            \State $cval \gets \textbf{pickAny}()$
          \Else
            \State $cval \gets \textbf{pickLargest}(MV)$
          \EndIf
         \State \SendTo{$\langle \texttt{ACCEPT}, crnd, cval \rangle$}
                       {$A$}
        \EndIf
      \EndIf
    \EndOn

  \end{algorithmic}
\end{algorithm}

First is the initialization for the proposer. It has access to the set of
all acceptors $A$.  It also sets the current round number $crnd$ to
zero, but it must be a unique value per Paxos node.
Equations \ref{equation:crnd_i} and \ref{equation:crnd_mod_N} show how we
obtain a sequence of unique numbers.

Upon receiving a \texttt{TRUST} message from $\Omega_c$, it will pick the
proposal number larger than $crnd$, reset the set of
$\langle round, vote~value\rangle$ tuples and then send a
\texttt{PREPARE} message to all acceptors $A$.  Finally, it will
send a \texttt{PREPARE} message to all acceptors.

\begin{algorithm}
  \caption{Classic crash Paxos --- Acceptor $a$}
  \label{algorithm:paxos.full.acceptor}
  \begin{algorithmic}
    \State $P$ \Comment{Set of proposers}
    \State $L$ \Comment{Set of learners}
    \State $rnd \gets 0$ \Comment{Highest round seen}
    \State $vrnd \gets \bot$ \Comment{Round in which value was last accepted}
    \State $vval \gets \bot$ \Comment{Value last accepted}
    \State

    \On{$\langle \texttt{PREPARE}, n \rangle$}
       {$\text{proposer}\ c$} \Comment{Phase 1b}
      \If{$n > rnd$}
         \State $rnd \gets n$
         \State \SendTo{$\langle \texttt{PROMISE}, rnd, vrnd, vval\rangle$}
                       {$c$}
      \EndIf
    \EndOn
    \State

    \On{$\langle \texttt{ACCEPT}, n, v \rangle$}
       {$\text{proposer}\ c$} \Comment{Phase 2b}
      \If{$n \geq rnd \wedge n \neq vrnd$}
        \State $rnd \gets n$
        \State $vrnd \gets n$
        \State $vval \gets v$
        \State \SendTo{$\langle \texttt{LEARN}, n, v \rangle$}
                      {$L$}
      \EndIf
    \EndOn
  \end{algorithmic}
\end{algorithm}


\section{Simplifying the Paxos implementation}

In this chapter we will look at a simplified implementation of Paxos as
given in algorithms \ref{algorithm:paxos.full.proposer} and
\ref{algorithm:paxos.full.acceptor}.

It has been simplified to serve our needs, i.e.~to be able to handle
\texttt{ACCEPT} and \texttt{LEARN}--messages.  We can therefore remove the
$vrnd$ altogether.  Also, each Paxos node in our system will take on all
three roles, so we don't need separate sets for the acceptors, learners and
proposers. We will instead use simply $N$ for the set of Paxos nodes.

We need $crnd$ to be a sequence of unique values per Paxos node.
Instead of initializing it to zero, we will set it to the node's
unique ID.  Then, in $\textbf{pickNext}$, we will simply increment $crnd$
with the total number of Paxos nodes in the system.  This is a common trick
to ensure that each and every $crnd$ will be unique in the system and has
the added benefit that we can deduce the node ID by taking
$crnd\ (\bmod\ |N|)$, or taking the $crnd$ modulus the number of Paxos nodes
$|N|$ in the system:

Given
\begin{gather}
  crnd_i = \left\{
             \begin{array}{ll}
               n_{id} & \mbox{for } i = 0 \\
               crnd_{i-1} + |N| & \mbox{for } i \geq 1
             \end{array}
           \right. , n \in N
  \label{equation:crnd_i}
\end{gather}
then, by definition,
\begin{gather}
  n_{id} \equiv crnd\ (\bmod\ |N|)\ \text{for}\ n \in N
  \label{equation:crnd_mod_N}
\end{gather}

where $n$ is the node and $N$ is the set of all nodes.  This leads to our
definition of $\textbf{pickNext}$ in algorithm
\ref{algorithm:paxos.simple.pickNext}.

\begin{algorithm}
  \caption{Definition of \textbf{pickNext} based on equation \ref{equation:crnd_mod_N}}
  \label{algorithm:paxos.simple.pickNext}
  \begin{algorithmic}
    \State $N$ \Comment{The set of all Paxos nodes}
    \State $n_{id} \gets \text{Unique Paxos node id}$
    \State $crnd \gets n_{id}$ \Comment{Replaces initialization of $crnd$ in algorithm \ref{algorithm:paxos.full.proposer}}
    \State
    \Function{$\textbf{pickNext}$}{}
      \State $\textbf{return}\ crnd + |N|$ \Comment{Unique per equation \ref{equation:crnd_mod_N}}
    \EndFunction
  \end{algorithmic}
\end{algorithm}

As we only intend to show that we can implement \texttt{ACCEPT} and
\texttt{LEARN}, we can ignore \texttt{TRUST}, \texttt{PROMISE} and
\texttt{PREPARE}--messages.  This leaves us with a very simple algorithm.

\begin{algorithm}
  \caption{Simplified algorithm for processing \texttt{ACCEPT}--messages}
  \label{algorithm:paxos.simple.acceptor}
  \begin{algorithmic}
    \State $N$\Comment{The set of Paxos nodes}
    \State $rnd \gets 0$ \Comment{Current round number}
    \State $vval \gets \bot$ \Comment{Packet ID of last round}
    \State

    \On{$\langle \texttt{ACCEPT}, n, v \rangle$}{$leader$}
      \If{$n \geq rnd$} % \wedge n \neq vrnd$}
        \State $rnd\gets n$
        \State $vval\gets v$ \Comment{The client packet ID}
        \ForIn{$node$}{$N$}
           \State \SendTo{$\langle \texttt{LEARN}, n, v \rangle$}
                         {$node$}
        \EndForIn
      \EndIf
    \EndOn
  \end{algorithmic}
\end{algorithm}

As for handling \texttt{LEARN}--messages, we can proceed to send the last
fragment of the client packet to the end--hosts when we have received a
learn from a majority.

\begin{algorithm}
  \caption{Simplified algorithm for processing \texttt{LEARN}--messages}
  \label{algorithm:paxos.simple.learner}
  \begin{algorithmic}
    \State $H$ \Comment{The set of end--hosts connected to this switch}
    \State

    \On{$\langle \texttt{LEARN}, n, v \rangle$}{$acceptor$}
      \If{$got\_{}majority(n)$}
        \ForIn{$host$}{$H$}
          \State \SendTo{$ last\_{}fragment(v) $}{$host$}
        \EndForIn
      \EndIf
    \EndOn
  \end{algorithmic}
\end{algorithm}

\section{Implementing simplified Paxos in Forth}

We will implement algorithms \ref{algorithm:paxos.simple.acceptor} 
and \ref{algorithm:paxos.simple.learner} in a combination of OpenFlow
matches and Forth.

\subsection{Paxos message packets}

For transmitting Paxos messages between the switches, we don't need to use
the IP--protocol.  A nice trick in OpenFlow is just to use Ethernet packets
and identify them by marking the Ethernet type field with a special value.
The packet payload will then consist of consecutive 32--bit values: The type of
Paxos message (\texttt{ACCEPT} or \texttt{LEARN} and their parameters.
This will make it easy for the switches to extract the contents.
Of course, since we don't use IP, we can only exchange these packets on a
local network.  If we wanted to distribute the switches across the network,
we would have to use IP.

\begin{table}[H]
  \centering
  \begin{tabular}{l|l|l|l|l|}
    \hline \dots & \textbf{Ethernet type} & \dots & \textbf{Payload} \\
    \hline \dots & \texttt{PAXOS HELLO}  & \dots & $ \langle\ node_{id},\ leader? \rangle $ \\
    \hline \dots & \texttt{PAXOS ACCEPT} & \dots & $ \langle\ rnd,\ packet_{id}\ \rangle $ \\
    \hline \dots & \texttt{PAXOS LEARN}  & \dots & $ \langle\ rnd,\ packet_{id}\ \rangle $ \\
    \hline
  \end{tabular}

  \caption{The structure of Paxos messages in Ethernet packets.}
  \label{table:paxos.ethernet.packet}
\end{table}
\todo{We need to add more Ethernet frame/packet headers here}

The payload is simply a flat vector of unsigned 32--bit integers.  The length
of the vectors are determined by the type of message.  For practical
purposes (being that we are developing on Intel x86--CPUs) we'll use
little--endian numbers, although a better alternative would be to go for
\textit{network order}---which is big--endian\footnote{Our goal is to
demonstrate the \textit{feasibility} of our approach, so we have deemed it
wise to avoid having to deal with endianness--conversion.}.

\begin{table}[H]
  \centering
  \begin{tabular}{|l|l|l|l|}
    \hline \textbf{Type} & \textbf{Parameter 1} & \textbf{Parameter 2} \\
           16 bits & 32 bits & 32 bits \\
    \hline \texttt{PAXOS HELLO} & $node_{id}$ & $leader?$ \\
    \hline \texttt{PAXOS ACCEPT} & $rnd$ & $packet_{id}$ \\
    \hline \texttt{PAXOS LEARN} & $rnd$ & $packet_{id}$ \\
    \hline
  \end{tabular}
  \caption{Structure of Paxos message payloads}
  \label{table:paxos.payload.structure}
\end{table}

At this point we
could debate whether to support wider values, e.g.~64--bit values.
This is not important for our demonstration.  A good solution would be to
allow for these values to roll around to zero again, but that would require
some changes to our algorithms.

The corresponding structure in C, after extracting the Ethernet type and
parameters, would be

\begin{figure}[H]
  \begin{Verbatim}
  struct paxos_message {
      uint16_t paxos_type;
      uint32_t params[2];
  };
  \end{Verbatim}
  \caption{C structure for a Paxos message with parameters.}
  \label{struct:paxos.message}
\end{figure}

As the structure above is defined in the C language, the padding will be
implicit by the rules of the C programming language standard and
platform\footnote{On my OS X x86\_{}64 computer, the size of the structure
is 12 bytes---i.e.,~no padding, as it aligns on a word boundary.}.

The reason we use two octets (16 bits) for the \texttt{paxos\_{}type} field
is that this will be actually be placed in the \textit{Ethernet type} field
of an Ethernet packet, and this is 16 bits wide \cite{IEEE.802.3}.

If we intended to implement full Paxos, we could simply add more message
types to the above structure and more parameters.

\subsection{OpenFlow matching rules}

We need several OpenFlow matching rules for this to work.

First, when a switch gets a client request (a packet from the WAN) it needs
to add flow table entries that forwards the packet to the leader.

When the system starts up, the switches need to announce themselves to each
other and learn which ports they are on.  For this we use the
\texttt{HELLO}--message given in table \ref{table:paxos.ethernet.packet}.
In a full Paxos implementation, the system would then perform leader
election.  That is out of scope for this thesis, so we will just designate
the first switch as the leader.  We also simplify the system further by
letting each switch know ahead how many other Paxos nodes there are---and
this will be static throughout the lifetime of the system\footnote{A full
Paxos implementation would also implement functionality for keeping tabs
on the liveness of each node.  OpenFlow has some limited support of
notifying the controllers when link status changes.  Also, a
production--quality system would allow for nodes to join and leave the
system.}.

\begin{table}[H]
  \centering
  \begin{tabular}{|l|}
    \hline \textbf{Flow table entry} \\
    \hline Forward client requests to leader \\
    \hline
  \end{tabular}

  \caption{OpenFlow flow table entries.}
  \label{table:paxos.flowtable.entries}
\end{table}

We also need entries for matching Paxos messages and react on these.
This is done by inserting entries that match on Ethernet type
\texttt{PAXOS} and ingress port from the leader.
The action will be to go to a new entry that looks at what kind of Paxos
message we have received\footnote{An optimization trick would be to
combine the Paxos packet type identifier with the Paxos message type and put
them both in the Ethernet type field.  Then we could use existing OpenFlow
matching instead of having to extract the Paxos message type.}.

Finally, when matching on Paxos message types, we would execute the Forth
bytecode and forward packets based on the return value from the code.

\subsection{New OpenFlow actions}

\todo{List opp nye actions her}
For the system to perform well, we don't want to store client packets in the
switch or the controller.  Instead, it would be nice if we could just pass
along client packets directly down to the end--hosts.

However, this means that the hosts will process the packets before we have a
chance to perform Paxos ordering.

We propose a neat solution to this problem.  When a switch receives a client
message, it will immediately perform IP--fragmentation of the message and
send the first fragment to the hosts.  The hosts networking stack will then
buffer the packet and wait for the last fragment.

When the Paxos consensus algorithm terminates, we will send the last
fragment down to the host, which will then pass the packet up the stack to
the server program.

We still need to store fragments, but if we choose the fragmentation offset
wisely, we need only store very small fragments.

The downside to this is that we break MTU rules, and some systems may behave
strange---or not at all.  But for our purposes we think this is a good
solution.

For this we need some new OpenFlow actions for fragmenting packets, storing
them and then forwarding the stored remaining fragment.

\begin{table}[H]
  \centering
  \begin{tabular}{|l|l|l|}
    \hline \textbf{Action} & \textbf{Parameters} & \textbf{Description} \\
    \hline Fragment packet & buffer id, fragment offset & ... \\
    \hline Defragment packet & buffer id, buffer id & ... \\
    \hline Store fragment in table & buffer id & ... \\
    \hline Retrieve fragment from table & buffer id & ... \\
    \hline
  \end{tabular}

  \caption{New OpenFlow actions.}
  \label{table:openflow.new.actions}
\end{table}

We also need new OpenFlow protocol messages so that the controller is able
to install flows with these new actions.  However, because of the scope of
this thesis, we will simply store these actions directly in OpenVSwitch and
pretend that these actions and flow entries came from the
controller\footnote{While trivial, this takes a little work to do fully.
One would first have to modify the OpenFlow protocol with new actions,
implement them and then do the same modifications on the controller.}.

\subsection{The switch data table}

Since each Paxos node needs to remember values for the round number, number
of nodes and so on, we propose that we add a simple table to each switch.

This is done by modifying the OpenVSwitch source code.

To conserve memory, we propose that each switch gets a table with 256
entries containing 32--bit values, for a total of 1024 bytes of memory.

OpenVSwitch needs to expose internally functions for manipulating this table
to Forth.  Our Forth code can then store the node id at location 0, round
numbers at location 1 and so on.

\section{The Paxos message handlers}

The \textbf{pickNext} algorithm is trivial and can be translated directly to
Forth.  The value $|N|$ needs to be set in an initialization word,
while $crnd$ must be synchronized with its value in the switch's data table.

\begin{figure}[H]
  \centering
  \begin{Verbatim}
  variable |N|
  variable crnd

  : pickNext ( -- crnd + |N| )
      \ Calculate the next value of crnd
      crnd @ |N| @ + ;
  \end{Verbatim}
  \caption{Implementation of \textbf{pickNext} (algorithm
      \ref{algorithm:paxos.simple.pickNext}) in Forth.}
  \label{program.forth.pickNext}
\end{figure}

The handling of \texttt{ACCEPT}--messages will be done in a combination of
Forth code and OpenFlow matching.  When the controller learns which port the
leader is on, it will install a flow entry to match on
\texttt{ACCEPT}--messages from the Paxos leader:

\begin{table}[H]
  \centering
  \begin{tabular}{l|l|l|l|l|}
    \hline
      \dots &
      \textbf{Ethernet type} &
      \dots &
      \textbf{Ethernet source} &
      \textbf{Action}
      \\
    \hline
      \dots &
      $\texttt{PAXOS ACCEPT}$
      & \dots
      & Leader MAC address
      & Execute program \ref{program:forth.on-accept}
      \\
    \hline
  \end{tabular}
  \caption{Flow entry matching rule for \texttt{ACCEPT}--messages.}
  \label{table:matching.simple.accept}
\end{table}

The code itself is straight--forward, except for the fact that $rnd$ and
$vval$ are not local Forth variables, but are actually stored in the
switch's data table\footnote{There are several ways of achieving this.
Either we can create Forth words for accessing the data table directly.
This method is explicit and easy.  The other way is to add code to have
the Forth VM mark certain variables to be automatically accessed from the
data table.}.

\begin{figure}[H]
  \centering
  \begin{Verbatim}
  variable node_id
  variable vval

  \ MAC addresses for switches
  \ These are stored in the data table at known locations
  10 data.table@ mac.s1
  11 data.table@ mac.s2
  12 data.table@ mac.s3

  \ Duplicate topmost two items
  : dup2 ( a b -- a b a b )
      over over ;

  : on_accept ( n v -- )
      swap dup                             ( n v -- v n n )
      rnd @ >= if                          ( v n n -- v n )
          dup rnd !                        ( v n -- v n ; save rnd)
          over vval !                      ( v n -- v n ; save vval)
          swap                             ( v n -- n v )

          \ Send LEARN to switches
          dup2 mac.s1 paxos.learn openflow.flood
          dup2 mac.s2 paxos.learn openflow.flood
          dup2 mac.s3 paxos.learn openflow.flood
      else
          drop drop ( v n -- )
      then ;
  \end{Verbatim}
  \caption{Implementation of \texttt{on\_{}accept} in Forth
            (algorithm \ref{algorithm:paxos.simple.acceptor}).}
  \label{program:forth.on-accept}
\end{figure}

Program \ref{program:forth.on-accept} \vpageref{program:forth.on-accept}
uses the word \texttt{paxos.learn} (program \ref{program:forth.paxos.learn})
to construct an Ethernet packet with the
Ethernet type set to \texttt{PAXOS.LEARN} and its payload containing the two
32--bit values $\langle v, n \rangle$.

\begin{figure}[H]
  \centering
  \begin{Verbatim}
  : paxos.learn ( addr n v -- Ethernet packet )
      2 paxos.pack32          ( addr n v -- addr payload )
      paxos.eth_type.learn    ( addr payload -- addr payload ethtype )
      swap paxos.eth_packet ; ( addr payload ethtype -- ethernet_packet )
  \end{Verbatim}
  \caption{Implementation of \texttt{paxos.learn} for creating a
    \texttt{PAXOS LEARN} packet}
  \label{program:forth.paxos.learn}
\end{figure}

The payload is created using
\texttt{2 paxos.pack32} (\textit{"pack two 32--bit values"}) and the message
is sent out using \texttt{openflow.flood}.  The two previous words are calls
into C.

In the same manner, we can create definitions for \texttt{paxos.accept} and
\texttt{paxos.hello} (programs \ref{program:forth.paxos.accept} and
\ref{program:forth.paxos.hello}, respectively).

\begin{figure}[H]
  \centering
  \begin{Verbatim}
  : paxos.accept ( addr n v -- Ethernet packet )
      2 paxos.pack32
      paxos.eth_type.accept
      swap paxos.eth_packet ;
  \end{Verbatim}
  \caption{Implementation of \texttt{paxos.accept} for creating a
    \texttt{PAXOS ACCEPT} packet}
  \label{program:forth.paxos.accept}
\end{figure}

\begin{figure}[H]
  \centering
  \begin{Verbatim}
  : paxos.hello ( addr node isleader -- Ethernet packet )
      2 paxos.pack32
      paxos.eth_type.hello
      swap paxos.eth_packet ;
  \end{Verbatim}
  \caption{Implementation of \texttt{paxos.hello} for creating a
    \texttt{PAXOS HELLO} packet}
  \label{program:forth.paxos.hello}
\end{figure}

Continuing in this manner, we can make code for \texttt{on\_{}learn}.

\begin{figure}[H]
  \centering
  \begin{Verbatim}
  \ Start of number of received learns
  \ E.g. at table[100] we have number of learns for rnd=0,
  \ etc.
  100 constant index.learned

  \ Calculate location of rnd data table
  : rnd.index ( rnd -- index )
    index.learned + ;

  \ Increments number of learns for given round number
  : inc.learns   ( rnd -- )
      rnd.index  ( rnd -- index )
      dup table@ ( index -- index value )
      +1 swap    ( index value -- value+1 index )
      table!     ( value+1 index -- ) ;

  : got.majority?       ( rnd -- true/false )
      rnd.index table@  ( rnd -- learns )
      |N| 2 / > if      \ Is learns > |N|/2 ?
          -1            \ True
      else
           0            \ False
      then ;

  : on_learn ( n v -- )
      over got.majority? if
          get.fragment openflow.flood.hosts
      else
          drop
      then ;
  \end{Verbatim}
  \caption{Implementation of \texttt{on\_{}learn} in Forth (algorithm \ref{algorithm:paxos.simple.learner}).}
  \label{program:forth.on-learn}
\end{figure}

\subsection{Why Forth?}

\todo{Insert a "defense" of why we chose Forth, and why we didn't implement
everything in OpenFlow}

What we want to avoid is to implement a complete, Turing--complete
programming language on the switch.  If that was our intention, we should
simply have used a platform that already had that, like Intel's NetVM
platform or NetFPGA\todo{Finn ut om flere alternative, og sjekk opp at disse
  nevnte er aktuelle}.

Instead, what we want is to provide \textit{simple} primitives that can be
implemented to run \textit{efficiently} on the hardware---requiring little
memory and few cycles per operation---while still being useful for other
networking protocols. (back up this statement on the last part)

In fact, our solution can, in fact, be implemented in a branchless manner on the
switch CPU, meaning that one can fill up the instruction pipeline for
maxiumem performance.  Our tables are simple vectors, meaning they
have constant time read and write operations and use little memory
(giving the benefit of improved memory locality).  In addition, the
low--level read and write instructions require extremely few cycles to run.

We think this is a good implementation for fastidious hardware implementors.

\subsection{Example of a full networking flow}

Now we will look at how an example client request will flow through the
system.

First the client sends an IP--packet to a switch.
The switch will then fragment the packet, send the first and largest
fragment to its hosts and forward it to all the other switches\todo{Dette er
litt annerledes. Og vi må sørge for at når de to andre switchene får
pakken så sender de den ikke videre}.

The end--hosts will receive an IP--fragment, store it and wait for the
remaining fragment.

When the leader receives a client packet, it will initiate the Paxos
algorithm.  In our simplified version of Paxos, it will then send
\texttt{ACCEPT} messages to the other two switches.

These switches will then send out \texttt{LEARN}--messages.
When a switch has received a majority of \texttt{LEARN}s, it will proceed to
send the last fragment down to its hosts.  The hosts will then combine the
fragments and pass the packet to the application.

The applications will then process the packet and, optionally, send back a
reply.\todo{Skal vi se bort fra hvordan vi velger ut svar fra endesystemene
og sender svar til klienten? Eller skal vi bare legge inn flows sånn at
kun den som mottok opprinnelig pakke kan svare klienten?}

\todo{Legg inn illustrasjoner her}

What we have accomplished here is using Paxos for ordering the client
requests down to the hosts, so that each host will receive packets in the
same order.  To test this, we will run simulations where several clients
send requests to the hosts. After some time, the state of each host should
be equal to each other.

\section{The final set of flow entries}

% Reglene må bli sånn
% - slaver: fra klient? fragment, send frag1 til hosts, forward til alle %   switcher
% - fra host? ...
% - paxos hello? store mac address (l2 learning), address of leader i table


\begin{table}[H]
  \centering
  \begin{tabular}{|l|l|}
    \hline \textbf{Match} & \textbf{Action} \\
    \hline From client & Fragment, store fragment 2 w/crnd, send fragment 1 to hosts \\
                       & Execute send--accept program \\
    \hline From host & Forward to client (TODO: Ignore, only allow one reply) \\
    \hline PAXOS HELLO & Store MAC address and node id of switch \\
    \hline PAXOS LEARN & Execute program on--learn \\
    \hline
  \end{tabular}
  \caption{The final flow table for the Paxos leader.}
  \label{table:complete.match.leader}
\end{table}

\begin{table}[H]
  \centering
  \begin{tabular}{|l|l|}
    \hline \textbf{Match} & \textbf{Action} \\
    \hline From client & Fragment, store fragment 2 w/crnd, send fragment 1 to hosts \\
                       & Forward to leader \\
    \hline From host & Forward to client (TODO: Ignore, only allow one reply) \\
    \hline PAXOS HELLO from any & Store MAC address, node id and leader--flag \\
    \hline PAXOS LEARN from any & Execute program on--learn \\
    \hline PAXOS ACCEPT from leader & Execute program on--accept \\
    \hline
  \end{tabular}
  \caption{The final flow table for Paxos slaves.}
  \label{table:complete.match.slave}
\end{table}
